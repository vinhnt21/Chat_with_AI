import streamlit as st
import os
from google import genai
from google.genai import types
from datetime import datetime


# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="DeepSeek",
    page_icon="ü§ñ",
    layout="wide"
)

# Kh·ªüi t·∫°o session state variables
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "conversation_start_time" not in st.session_state:
    st.session_state.conversation_start_time = datetime.now().strftime("%Y%m%d_%H%M%S")

# Title
st.title("ü§ñ DeepSeek Chat")
st.markdown("---")

# Sidebar cho c·∫•u h√¨nh
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh")
    
    # API Key input
    api_key = st.text_input(
        "üîë Gemini API Key",
        type="password",
        help="Nh·∫≠p API key c·ªßa b·∫°n ƒë·ªÉ s·ª≠ d·ª•ng Gemini API"
    )
    
    # Model selection
    model_options = [
        "gemini-2.5-pro",
        "gemini-2.5-flash"
    ]
    selected_model = st.selectbox(
        "ü§ñ Ch·ªçn Model",
        model_options,
        index=0
    )
    
    # Temperature slider
    temperature = st.slider(
        "üå°Ô∏è Temperature",
        min_value=0.0,
        max_value=2.0,
        value=1.0,
        step=0.1,
        help="ƒê·ªô s√°ng t·∫°o c·ªßa AI (0.0 = conservative, 2.0 = creative)"
    )
    
    # Thinking budget
    thinking_budget = st.slider(
        "üß† Thinking Budget",
        min_value=-1,
        max_value=100,
        value=-1,
        help="Th·ªùi gian suy nghƒ© c·ªßa AI (-1 = kh√¥ng gi·ªõi h·∫°n)"
    )
    
    # Clear chat button
    if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.conversation_start_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.rerun()
    
    # Chat history info
    st.markdown("---")
    st.subheader("üìä Th√¥ng tin Chat")
    
    if st.session_state.chat_history:
        total_messages = len(st.session_state.chat_history)
        user_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "user"])
        ai_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "assistant"])
        
        st.metric("T·ªïng tin nh·∫Øn", total_messages)
        st.metric("Tin nh·∫Øn c·ªßa b·∫°n", user_messages)
        st.metric("Ph·∫£n h·ªìi AI", ai_messages)
        
        # Export chat history
        if st.button("üì• Xu·∫•t l·ªãch s·ª≠ chat", use_container_width=True):
            chat_export = "\n".join([
                f"{'üßë‚Äçüíª User' if msg['role'] == 'user' else 'ü§ñ AI'}: {msg['content']}\n"
                for msg in st.session_state.chat_history
            ])
            st.download_button(
                label="üíæ T·∫£i v·ªÅ file text",
                data=chat_export,
                file_name=f"chat_history_{st.session_state.conversation_start_time}.txt",
                mime="text/plain",
                use_container_width=True
            )
    else:
        st.info("Ch∆∞a c√≥ tin nh·∫Øn n√†o")
    
    st.markdown("---")

# Main chat interface
st.header("üí¨ Chat")

# Display chat history
chat_container = st.container()
with chat_container:
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            with st.chat_message("user"):
                st.write(message["content"])
        else:
            with st.chat_message("assistant"):
                st.write(message["content"])

# Chat input
user_input = st.chat_input("Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n...")

# Function to generate response
def generate_response(client, model, chat_history, temp, thinking_budget_val):
    # Convert chat history to Contents format for the API
    contents = []
    
    for message in chat_history:
        if message["role"] == "user":
            contents.append(
                types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=message["content"])],
                )
            )
        elif message["role"] == "assistant":
            contents.append(
                types.Content(
                    role="model",  # Gemini uses "model" instead of "assistant"
                    parts=[types.Part.from_text(text=message["content"])],
                )
            )
    
    generate_content_config = types.GenerateContentConfig(
        thinking_config=types.ThinkingConfig(
            thinking_budget=thinking_budget_val,
        ),
        response_mime_type="text/plain",
        temperature=temp,
    )
    
    return client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    )

# Process user input
if user_input and api_key:
    # Add user message to chat history
    st.session_state.chat_history.append({
        "role": "user",
        "content": user_input
    })
    
    # Display user message
    with st.chat_message("user"):
        st.write(user_input)
    
    # Generate and display AI response
    with st.chat_message("assistant"):
        try:
            # Initialize client
            client = genai.Client(api_key=api_key)
            
            # Create placeholder for streaming response
            response_placeholder = st.empty()
            full_response = ""
            
            # Generate streaming response
            stream = generate_response(
                client, 
                selected_model, 
                st.session_state.chat_history, 
                temperature, 
                thinking_budget
            )
            
            # Stream the response
            for chunk in stream:
                if chunk.text:
                    full_response += chunk.text
                    response_placeholder.write(full_response)
            
            # Add AI response to chat history
            st.session_state.chat_history.append({
                "role": "assistant", 
                "content": full_response
            })
            
        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")
            st.error("Vui l√≤ng ki·ªÉm tra API key v√† th·ª≠ l·∫°i.")

elif user_input and not api_key:
    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p API key trong sidebar ƒë·ªÉ s·ª≠ d·ª•ng!")

# Information section
with st.expander("‚ÑπÔ∏è H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
    st.markdown("""
    **C√°ch s·ª≠ d·ª•ng ·ª©ng d·ª•ng:**
    
    1. **Nh·∫≠p API Key**: Trong sidebar, nh·∫≠p API key Gemini c·ªßa b·∫°n
    2. **Ch·ªçn Model**: Ch·ªçn model Gemini ph√π h·ª£p
    3. **ƒêi·ªÅu ch·ªânh Temperature**: Thay ƒë·ªïi ƒë·ªô s√°ng t·∫°o c·ªßa AI
    4. **Chat**: Nh·∫≠p tin nh·∫Øn v√† nh·∫•n Enter ƒë·ªÉ chat
    
    **L·∫•y API Key:**
    - Truy c·∫≠p [Google AI Studio](https://aistudio.google.com/apikey)
    - T·∫°o API key m·ªõi
    - Copy v√† paste v√†o ·ª©ng d·ª•ng
    
    **Models c√≥ s·∫µn:**
    - `gemini-2.5-pro`: Model m·∫°nh nh·∫•t, ph√π h·ª£p cho c√°c t√°c v·ª• ph·ª©c t·∫°p
    - `gemini-2.5-flash`: Model nhanh, ph√π h·ª£p cho chat th√¥ng th∆∞·ªùng
    """)

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ƒê∆∞·ª£c x√¢y d·ª±ng v·ªõi ‚ù§Ô∏è s·ª≠ d·ª•ng Streamlit v√† Gemini API/"
    "AIzaSyDTxyIyE_j-6-K_FycZKcLJsAiZNy----/"
    "AIzaSyCaFFTGjFLPojwbglFRuwLS3-Q-aXk----/"
    "AIzaSyAaCUt4nMWM43fILvu3RS0ADQZufMN----/"

    "</div>", 
    unsafe_allow_html=True
) 