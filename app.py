import streamlit as st
import os
from google import genai
from google.genai import types
from datetime import datetime
import tempfile


# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="DeepSeek",
    page_icon="ü§ñ",
    layout="wide"
)

# Kh·ªüi t·∫°o session state variables
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "conversation_start_time" not in st.session_state:
    st.session_state.conversation_start_time = datetime.now().strftime("%Y%m%d_%H%M%S")

# Title
st.title("ü§ñ DeepSeek Chat")
st.markdown("---")

# Sidebar cho c·∫•u h√¨nh
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh")
    
    # API Key input
    api_key = st.text_input(
        "üîë Gemini API Key",
        type="password",
        help="Nh·∫≠p API key c·ªßa b·∫°n ƒë·ªÉ s·ª≠ d·ª•ng Gemini API"
    )
    
    # Model selection
    model_options = [
        "gemini-2.5-pro",
        "gemini-2.5-flash"
    ]
    selected_model = st.selectbox(
        "ü§ñ Ch·ªçn Model",
        model_options,
        index=0
    )
    
    # Temperature slider
    temperature = st.slider(
        "üå°Ô∏è Temperature",
        min_value=0.0,
        max_value=2.0,
        value=1.0,
        step=0.1,
        help="ƒê·ªô s√°ng t·∫°o c·ªßa AI (0.0 = conservative, 2.0 = creative)"
    )
    
    # Thinking budget
    thinking_budget = st.slider(
        "üß† Thinking Budget",
        min_value=-1,
        max_value=100,
        value=-1,
        help="Th·ªùi gian suy nghƒ© c·ªßa AI (-1 = kh√¥ng gi·ªõi h·∫°n)"
    )
    
    # Clear chat button
    if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.conversation_start_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.rerun()
    
    # Chat history info
    st.markdown("---")
    st.subheader("üìä Th√¥ng tin Chat")
    
    if st.session_state.chat_history:
        total_messages = len(st.session_state.chat_history)
        user_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "user"])
        ai_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "assistant"])
        
        st.metric("T·ªïng tin nh·∫Øn", total_messages)
        st.metric("Tin nh·∫Øn c·ªßa b·∫°n", user_messages)
        st.metric("Ph·∫£n h·ªìi AI", ai_messages)
        
        # Export chat history
        if st.button("üì• Xu·∫•t l·ªãch s·ª≠ chat", use_container_width=True):
            chat_export = "\n".join([
                f"{'üßë‚Äçüíª User' if msg['role'] == 'user' else 'ü§ñ AI'}: {msg['content']}\n"
                for msg in st.session_state.chat_history
            ])
            st.download_button(
                label="üíæ T·∫£i v·ªÅ file text",
                data=chat_export,
                file_name=f"chat_history_{st.session_state.conversation_start_time}.txt",
                mime="text/plain",
                use_container_width=True
            )
    else:
        st.info("Ch∆∞a c√≥ tin nh·∫Øn n√†o")
    
    st.markdown("---")

# Main chat interface
st.header("üí¨ Chat")

# File upload section
with st.expander("üìé G·ª≠i file (·∫£nh, √¢m thanh, video, PDF...)", expanded=False):
    uploaded_file = st.file_uploader(
        "Ch·ªçn file ƒë·ªÉ g·ª≠i",
        type=['jpg', 'jpeg', 'png', 'gif', 'webp', 'mp3', 'wav', 'mp4', 'avi', 'mov', 'pdf', 'txt', 'doc', 'docx'],
        help="H·ªó tr·ª£: ·∫£nh (JPG, PNG, GIF, WebP), √¢m thanh (MP3, WAV), video (MP4, AVI, MOV), t√†i li·ªáu (PDF, TXT, DOC, DOCX)"
    )
    
    # File description input
    if uploaded_file:
        file_description = st.text_input(
            "M√¥ t·∫£ ho·∫∑c c√¢u h·ªèi v·ªÅ file (t√πy ch·ªçn)",
            placeholder="V√≠ d·ª•: H√£y m√¥ t·∫£ ·∫£nh n√†y, Ph√¢n t√≠ch n·ªôi dung audio...",
            key="file_description"
        )
        
        # Send file button
        send_file = st.button("üì§ G·ª≠i file", type="primary", use_container_width=True)
    else:
        send_file = False
        file_description = ""

# Display chat history
chat_container = st.container()
with chat_container:
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            with st.chat_message("user"):
                # Display text content
                if message.get("content"):
                    st.write(message["content"])
                
                # Display file info if exists
                if message.get("file_info"):
                    file_info = message["file_info"]
                    st.info(f"üìé File: {file_info['name']} ({file_info['size']} bytes)")
                    
                    # Show image preview if it's an image
                    if file_info.get("type", "").startswith("image/"):
                        if file_info.get("local_path") and os.path.exists(file_info["local_path"]):
                            st.image(file_info["local_path"], width=300)
        else:
            with st.chat_message("assistant"):
                st.write(message["content"])

# Chat input
user_input = st.chat_input("Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n...")

# Function to generate response
def generate_response(client, model, chat_history, temp, thinking_budget_val, uploaded_file_obj=None):
    # Convert chat history to Contents format for the API
    contents = []
    
    for message in chat_history:
        if message["role"] == "user":
            parts = [types.Part.from_text(text=message["content"])]
            
            # Add file if this message has one
            if message.get("gemini_file"):
                parts.append(message["gemini_file"])
            
            contents.append(
                types.Content(
                    role="user",
                    parts=parts,
                )
            )
        elif message["role"] == "assistant":
            contents.append(
                types.Content(
                    role="model",  # Gemini uses "model" instead of "assistant"
                    parts=[types.Part.from_text(text=message["content"])],
                )
            )
    
    generate_content_config = types.GenerateContentConfig(
        thinking_config=types.ThinkingConfig(
            thinking_budget=thinking_budget_val,
        ),
        response_mime_type="text/plain",
        temperature=temp,
    )
    
    return client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    )

def upload_file_to_gemini(client, file_path, file_name):
    """Upload file to Gemini and return file object"""
    try:
        uploaded_file = client.files.upload(file=file_path)
        return uploaded_file
    except Exception as e:
        st.error(f"‚ùå L·ªói khi upload file: {str(e)}")
        return None

# Process file upload
if send_file and uploaded_file and api_key:
    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # Initialize client
        client = genai.Client(api_key=api_key)
        
        # Upload file to Gemini
        with st.spinner("üì§ ƒêang upload file..."):
            gemini_file = upload_file_to_gemini(client, tmp_file_path, uploaded_file.name)
        
        if gemini_file:
            # Prepare message content
            message_content = file_description if file_description else f"ƒê√¢y l√† file {uploaded_file.name}"
            
            # Add user message with file to chat history
            file_info = {
                "name": uploaded_file.name,
                "size": uploaded_file.size,
                "type": uploaded_file.type,
                "local_path": tmp_file_path if uploaded_file.type.startswith("image/") else None
            }
            
            st.session_state.chat_history.append({
                "role": "user",
                "content": message_content,
                "file_info": file_info,
                "gemini_file": gemini_file
            })
            
            # Display user message with file
            with st.chat_message("user"):
                st.write(message_content)
                st.info(f"üìé File: {uploaded_file.name} ({uploaded_file.size} bytes)")
                
                # Show image preview if it's an image
                if uploaded_file.type.startswith("image/"):
                    st.image(uploaded_file, width=300)
            
            # Generate and display AI response
            with st.chat_message("assistant"):
                try:
                    # Create placeholder for streaming response
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    # Generate streaming response
                    stream = generate_response(
                        client, 
                        selected_model, 
                        st.session_state.chat_history, 
                        temperature, 
                        thinking_budget
                    )
                    
                    # Stream the response
                    for chunk in stream:
                        if chunk.text:
                            full_response += chunk.text
                            response_placeholder.write(full_response)
                    
                    # Add AI response to chat history
                    st.session_state.chat_history.append({
                        "role": "assistant", 
                        "content": full_response
                    })
                    
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file: {str(e)}")
        
        # Clean up temporary file after a delay (keep for image preview)
        if not uploaded_file.type.startswith("image/"):
            try:
                os.unlink(tmp_file_path)
            except:
                pass
                
    except Exception as e:
        st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file: {str(e)}")
    
    # Clear the file uploader by rerunning
    st.rerun()

elif send_file and not api_key:
    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p API key trong sidebar ƒë·ªÉ g·ª≠i file!")

elif send_file and not uploaded_file:
    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn file ƒë·ªÉ g·ª≠i!")

# Process user input
if user_input and api_key:
    # Add user message to chat history
    st.session_state.chat_history.append({
        "role": "user",
        "content": user_input
    })
    
    # Display user message
    with st.chat_message("user"):
        st.write(user_input)
    
    # Generate and display AI response
    with st.chat_message("assistant"):
        try:
            # Initialize client
            client = genai.Client(api_key=api_key)
            
            # Create placeholder for streaming response
            response_placeholder = st.empty()
            full_response = ""
            
            # Generate streaming response
            stream = generate_response(
                client, 
                selected_model, 
                st.session_state.chat_history, 
                temperature, 
                thinking_budget
            )
            
            # Stream the response
            for chunk in stream:
                if chunk.text:
                    full_response += chunk.text
                    response_placeholder.write(full_response)
            
            # Add AI response to chat history
            st.session_state.chat_history.append({
                "role": "assistant", 
                "content": full_response
            })
            
        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")
            st.error("Vui l√≤ng ki·ªÉm tra API key v√† th·ª≠ l·∫°i.")

elif user_input and not api_key:
    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p API key trong sidebar ƒë·ªÉ s·ª≠ d·ª•ng!")

# Information section
with st.expander("‚ÑπÔ∏è H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
    st.markdown("""
    **C√°ch s·ª≠ d·ª•ng ·ª©ng d·ª•ng:**
    
    1. **Nh·∫≠p API Key**: Trong sidebar, nh·∫≠p API key Gemini c·ªßa b·∫°n
    2. **Ch·ªçn Model**: Ch·ªçn model Gemini ph√π h·ª£p
    3. **ƒêi·ªÅu ch·ªânh Temperature**: Thay ƒë·ªïi ƒë·ªô s√°ng t·∫°o c·ªßa AI
    4. **Chat vƒÉn b·∫£n**: Nh·∫≠p tin nh·∫Øn v√† nh·∫•n Enter ƒë·ªÉ chat
    5. **G·ª≠i file**: S·ª≠ d·ª•ng ph·∫ßn "üìé G·ª≠i file" ƒë·ªÉ upload v√† ph√¢n t√≠ch file
    
    **L·∫•y API Key:**
    - Truy c·∫≠p [Google AI Studio](https://aistudio.google.com/apikey)
    - T·∫°o API key m·ªõi
    - Copy v√† paste v√†o ·ª©ng d·ª•ng
    
    **Models c√≥ s·∫µn:**
    - `gemini-2.5-pro`: Model m·∫°nh nh·∫•t, ph√π h·ª£p cho c√°c t√°c v·ª• ph·ª©c t·∫°p
    - `gemini-2.5-flash`: Model nhanh, ph√π h·ª£p cho chat th√¥ng th∆∞·ªùng
    
    **File ƒë∆∞·ª£c h·ªó tr·ª£:**
    - **·∫¢nh**: JPG, PNG, GIF, WebP
    - **√Çm thanh**: MP3, WAV
    - **Video**: MP4, AVI, MOV
    - **T√†i li·ªáu**: PDF, TXT, DOC, DOCX
    
    **M·∫πo s·ª≠ d·ª•ng file:**
    - Th√™m m√¥ t·∫£ c·ª• th·ªÉ cho file ƒë·ªÉ ƒë∆∞·ª£c ph·∫£n h·ªìi ch√≠nh x√°c h∆°n
    - V√≠ d·ª•: "M√¥ t·∫£ chi ti·∫øt n·ªôi dung ·∫£nh n√†y", "T√≥m t·∫Øt n·ªôi dung audio"
    """)

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ƒê∆∞·ª£c x√¢y d·ª±ng v·ªõi ‚ù§Ô∏è s·ª≠ d·ª•ng Streamlit v√† Gemini API/"
    "AIzaSyDTxyIyE_j-6-K_FycZKcLJsAiZNy----/"
    "AIzaSyCaFFTGjFLPojwbglFRuwLS3-Q-aXk----/"
    "AIzaSyAaCUt4nMWM43fILvu3RS0ADQZufMN----/"

    "</div>", 
    unsafe_allow_html=True
) 