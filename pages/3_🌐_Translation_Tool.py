import streamlit as st
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor
from utils.config import initialize_session_state, setup_sidebar, check_configuration
from utils.llm import get_llm_provider
from utils.db import get_all_prompts

# --- Cáº¥u hÃ¬nh trang ---
st.set_page_config(page_title="Translation Tool", layout="wide")
initialize_session_state()
setup_sidebar()
check_configuration()

st.title("ğŸŒ CÃ´ng cá»¥ Dá»‹ch thuáº­t & PhÃ¢n tÃ­ch")
st.write("Sá»­ dá»¥ng AI Ä‘á»ƒ dá»‹ch, tÃ³m táº¯t vÃ  rÃºt ra nhá»¯ng Ä‘iá»ƒm chÃ­nh tá»« vÄƒn báº£n.")

# --- Láº¥y provider vÃ  models ---
try:
    llm_provider = get_llm_provider(st.session_state.api_provider, st.session_state.api_key)
    available_models = llm_provider.get_models() if llm_provider else []
except (ValueError, Exception) as e:
    st.error(f"Lá»—i khá»Ÿi táº¡o LLM provider: {e}")
    st.stop()

# --- Cáº¥u hÃ¬nh cho translation tool ---
with st.expander("âš™ï¸ Cáº¥u hÃ¬nh Model vÃ  Prompts", expanded=False):
    col1, col2 = st.columns(2)
    
    with col1:
        selected_model = st.selectbox("Chá»n Model:", available_models, key="trans_model")
        target_language = st.selectbox(
            "NgÃ´n ngá»¯ Ä‘Ã­ch:", 
            ["Vietnamese", "English", "French", "German", "Spanish", "Chinese", "Japanese", "Korean", "Thai"],
            key="target_lang"
        )
        
    with col2:
        temperature = st.slider("Temperature:", 0.0, 1.0, 0.3, 0.05, key="trans_temp")

# --- Custom Prompts Section ---
with st.expander("ğŸ“Custom Prompts"):



    # Láº¥y prompts Ä‘Ã£ lÆ°u
    prompts_data = get_all_prompts()
    prompt_options = {p['name']: p['content'] for p in prompts_data}
    prompt_names = ["-- TÃ¹y chá»‰nh --"] + list(prompt_options.keys())

    col1, col2, col3 = st.columns(3)

    with col1:
        st.write("**Prompt Dá»‹ch thuáº­t:**")
        selected_translate_prompt = st.selectbox("Chá»n prompt cÃ³ sáºµn:", prompt_names, key="trans_prompt_select")
        
        if selected_translate_prompt == "-- TÃ¹y chá»‰nh --":
            translate_prompt = st.text_area(
                "Prompt dá»‹ch thuáº­t:",
                f"HÃ£y dá»‹ch vÄƒn báº£n sau sang {target_language}. Giá»¯ nguyÃªn Ã½ nghÄ©a vÃ  phong cÃ¡ch cá»§a vÄƒn báº£n gá»‘c. Chá»‰ tráº£ vá» báº£n dá»‹ch, khÃ´ng thÃªm giáº£i thÃ­ch:\n\n{{text}}",
                height=150,
                key="custom_trans_prompt"
            )
        else:
            translate_prompt = st.text_area(
                "Prompt dá»‹ch thuáº­t:",
                prompt_options[selected_translate_prompt] + f"\n\nDá»‹ch sang {target_language}:\n{{text}}",
                height=150,
                key="custom_trans_prompt"
            )

    with col2:
        st.write("**Prompt TÃ³m táº¯t:**")
        selected_summary_prompt = st.selectbox("Chá»n prompt cÃ³ sáºµn:", prompt_names, key="summary_prompt_select")
        
        if selected_summary_prompt == "-- TÃ¹y chá»‰nh --":
            summary_prompt = st.text_area(
                "Prompt tÃ³m táº¯t:",
                f"HÃ£y tÃ³m táº¯t vÄƒn báº£n sau thÃ nh 3-5 cÃ¢u chÃ­nh báº±ng {target_language}. Táº­p trung vÃ o nhá»¯ng Ä‘iá»ƒm quan trá»ng nháº¥t:\n\n{{text}}",
                height=150,
                key="custom_summary_prompt"
            )
        else:
            summary_prompt = st.text_area(
                "Prompt tÃ³m táº¯t:",
                prompt_options[selected_summary_prompt] + f"\n\nTÃ³m táº¯t báº±ng {target_language}:\n{{text}}",
                height=150,
                key="custom_summary_prompt"
            )

    with col3:
        st.write("**Prompt Tá»« vá»±ng hay:**")
        selected_vocab_prompt = st.selectbox("Chá»n prompt cÃ³ sáºµn:", prompt_names, key="vocab_prompt_select")
        
        if selected_vocab_prompt == "-- TÃ¹y chá»‰nh --":
            vocab_prompt = st.text_area(
                "Prompt tá»« vá»±ng:",
                f"Tá»« vÄƒn báº£n sau, hÃ£y trÃ­ch xuáº¥t 5-10 tá»«/cá»¥m tá»« hay vÃ  há»¯u Ã­ch nháº¥t. Vá»›i má»—i tá»«, hÃ£y cung cáº¥p:\n- Tá»« gá»‘c\n- PhiÃªn Ã¢m (náº¿u cáº§n)\n- NghÄ©a báº±ng {target_language}\n- VÃ­ dá»¥ sá»­ dá»¥ng\n\nVÄƒn báº£n:\n{{text}}",
                height=150,
                key="custom_vocab_prompt"
            )
        else:
            vocab_prompt = st.text_area(
                "Prompt tá»« vá»±ng:",
                prompt_options[selected_vocab_prompt] + f"\n\nTrÃ­ch xuáº¥t tá»« vá»±ng tá»«:\n{{text}}",
                height=150,
                key="custom_vocab_prompt"
            )

# --- Input Text ---
st.subheader("ğŸ“„ VÄƒn báº£n cáº§n xá»­ lÃ½")
input_text = st.text_area("DÃ¡n vÄƒn báº£n gá»‘c vÃ o Ä‘Ã¢y:", height=200, key="input_text")

# --- Processing Functions ---
def process_task(prompt_template, input_text, task_name):
    """Xá»­ lÃ½ má»™t task riÃªng láº» vá»›i LLM provider"""
    try:
        # Format prompt vá»›i input text
        formatted_prompt = prompt_template.replace("{text}", input_text)
        messages = [{"role": "user", "content": formatted_prompt}]
        
        # Táº¡o response tá»« LLM
        response_stream = llm_provider.chat_stream(
            messages=messages,
            model=selected_model,
            temperature=temperature,
            system_prompt=f"Báº¡n lÃ  má»™t chuyÃªn gia {task_name}. HÃ£y thá»±c hiá»‡n nhiá»‡m vá»¥ má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  chi tiáº¿t."
        )
        
        # Collect full response
        full_response = ""
        for chunk in response_stream:
            if chunk:  # Check if chunk is not empty
                full_response += chunk
        
        # Check if response is empty or contains error messages
        if not full_response.strip():
            return f"âš ï¸ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i cho {task_name}. Thá»­ chuyá»ƒn sang model khÃ¡c."
        
        if full_response.strip().startswith("âš ï¸") or full_response.strip().startswith("âŒ"):
            return full_response.strip()
            
        return full_response.strip()
    except Exception as e:
        error_message = str(e)
        if "safety" in error_message.lower() or "finish_reason" in error_message:
            return f"âš ï¸ {task_name} bá»‹ cháº·n bá»Ÿi bá»™ lá»c an toÃ n. Vui lÃ²ng thá»­ vÄƒn báº£n khÃ¡c hoáº·c model khÃ¡c."
        return f"âŒ Lá»—i xá»­ lÃ½ {task_name}: {error_message}"

# --- Main Processing ---
if st.button("ğŸš€ PhÃ¢n tÃ­ch ngay", type="primary", use_container_width=True):
    if not input_text.strip():
        st.error("Vui lÃ²ng nháº­p vÄƒn báº£n Ä‘á»ƒ phÃ¢n tÃ­ch.")
    else:
        # Process all tasks in parallel using ThreadPoolExecutor
        with st.spinner("AI Ä‘ang xá»­ lÃ½ táº¥t cáº£ cÃ¡c tÃ¡c vá»¥, vui lÃ²ng chá»..."):
            with ThreadPoolExecutor(max_workers=3) as executor:
                # Submit all tasks
                future_translate = executor.submit(process_task, translate_prompt, input_text, "dá»‹ch thuáº­t")
                future_summary = executor.submit(process_task, summary_prompt, input_text, "tÃ³m táº¯t")
                future_vocab = executor.submit(process_task, vocab_prompt, input_text, "trÃ­ch xuáº¥t tá»« vá»±ng")
                
                # Get results
                translate_result = future_translate.result()
                summary_result = future_summary.result()
                vocab_result = future_vocab.result()
        
        # Display results in 2 columns
        col_results, col_original = st.columns([0.6, 0.4])
        
        with col_results:
            st.subheader("ğŸ“Š Káº¿t quáº£ phÃ¢n tÃ­ch")
            # Create tabs for results
            tab1, tab2, tab3 = st.tabs(["ğŸŒ Báº£n dá»‹ch", "ğŸ“‹ TÃ³m táº¯t", "ğŸ“š Tá»« vá»±ng hay"])
            
            with tab1:
                st.write(f"**Báº£n dá»‹ch sang {target_language}:**")
                if translate_result.startswith("Lá»—i"):
                    st.error(translate_result)
                else:
                    st.success("âœ… Dá»‹ch thuáº­t hoÃ n táº¥t!")
                    st.markdown(translate_result)
                    
                    # Copy button
                    if st.button("ğŸ“‹ Copy báº£n dá»‹ch", key="copy_translate"):
                        st.code(translate_result)
            
            with tab2:
                st.write("**TÃ³m táº¯t ná»™i dung:**")
                if summary_result.startswith("Lá»—i"):
                    st.error(summary_result)
                else:
                    st.success("âœ… TÃ³m táº¯t hoÃ n táº¥t!")
                    st.info(summary_result)
                    
                    # Copy button
                    if st.button("ğŸ“‹ Copy tÃ³m táº¯t", key="copy_summary"):
                        st.code(summary_result)
            
            with tab3:
                st.write("**Tá»«/Cá»¥m tá»« Ä‘Ã¡ng chÃº Ã½:**")
                if vocab_result.startswith("Lá»—i"):
                    st.error(vocab_result)
                else:
                    st.success("âœ… TrÃ­ch xuáº¥t tá»« vá»±ng hoÃ n táº¥t!")
                    st.markdown(vocab_result)
                    
                    # Copy button
                    if st.button("ğŸ“‹ Copy tá»« vá»±ng", key="copy_vocab"):
                        st.code(vocab_result)
        
        with col_original:
            st.subheader("ğŸ“„ VÄƒn báº£n gá»‘c")
            st.write("*ÄÆ°á»£c format Ä‘á»ƒ tiá»‡n so sÃ¡nh:*")
            
            # Try to render as markdown first, fallback to plain text
            try:
                # Display as markdown for better formatting
                st.markdown("---")
                st.markdown(input_text)
                st.markdown("---")
                
                # Show text stats
                word_count = len(input_text.split())
                char_count = len(input_text)
                st.caption(f"ğŸ“ˆ Thá»‘ng kÃª: {word_count} tá»«, {char_count} kÃ½ tá»±")
                
                # Option to view as code/plain text
                if st.button("ğŸ‘ï¸ Xem dáº¡ng vÄƒn báº£n thuáº§n", key="view_plain"):
                    st.code(input_text)
                    
            except Exception as e:
                # If markdown rendering fails, show as plain text
                st.text_area("VÄƒn báº£n gá»‘c:", input_text, height=300, disabled=True, key="original_text_display")

# --- Additional Features ---
with st.expander("ğŸ’¡ HÆ°á»›ng dáº«n sá»­ dá»¥ng"):
    st.markdown("""
    **CÃ¡ch sá»­ dá»¥ng cÃ´ng cá»¥ dá»‹ch thuáº­t:**
    
    1. **Cáº¥u hÃ¬nh Model:** Chá»n model AI phÃ¹ há»£p vá»›i nhu cáº§u cá»§a báº¡n
    2. **Chá»n ngÃ´n ngá»¯ Ä‘Ã­ch:** Chá»n ngÃ´n ngá»¯ báº¡n muá»‘n dá»‹ch sang
    3. **TÃ¹y chá»‰nh Prompts:** 
       - Sá»­ dá»¥ng prompts cÃ³ sáºµn tá»« Prompt Manager
       - Hoáº·c tá»± viáº¿t prompts theo nhu cáº§u cá»¥ thá»ƒ
       - Sá»­ dá»¥ng `{text}` trong prompt Ä‘á»ƒ Ä‘Ã¡nh dáº¥u vá»‹ trÃ­ vÄƒn báº£n Ä‘áº§u vÃ o
    4. **Nháº­p vÄƒn báº£n:** Paste vÄƒn báº£n cáº§n xá»­ lÃ½ vÃ o Ã´ input
    5. **Cháº¡y phÃ¢n tÃ­ch:** Nháº¥n nÃºt "PhÃ¢n tÃ­ch ngay" Ä‘á»ƒ xá»­ lÃ½
    
    **Máº¹o:**
    - CÃ¡c tÃ¡c vá»¥ sáº½ cháº¡y song song Ä‘á»ƒ tá»‘i Æ°u thá»i gian
    - Báº¡n cÃ³ thá»ƒ copy káº¿t quáº£ tá»« tá»«ng tab
    - Äiá»u chá»‰nh temperature Ä‘á»ƒ kiá»ƒm soÃ¡t Ä‘á»™ sÃ¡ng táº¡o (tháº¥p = chÃ­nh xÃ¡c hÆ¡n)
    - Model khÃ¡c nhau cÃ³ thá»ƒ cho káº¿t quáº£ khÃ¡c nhau
    - AI sáº½ dá»‹ch toÃ n bá»™ ná»™i dung khÃ´ng giá»›i háº¡n Ä‘á»™ dÃ i
    
    **âš ï¸ Xá»­ lÃ½ lá»—i Safety Filter:**
    - **Google Gemini** cÃ³ bá»™ lá»c an toÃ n strict, cÃ³ thá»ƒ cháº·n má»™t sá»‘ ná»™i dung
    - Náº¿u gáº·p lá»—i "bá»‹ cháº·n bá»Ÿi bá»™ lá»c an toÃ n":
      - Thá»­ chuyá»ƒn sang **OpenAI**, **Anthropic** hoáº·c **DeepSeek**
      - Hoáº·c Ä‘iá»u chá»‰nh vÄƒn báº£n Ä‘áº§u vÃ o Ä‘á»ƒ trÃ¡nh tá»« ngá»¯ nháº¡y cáº£m
      - Sá»­ dá»¥ng prompts Ã­t "directive" hÆ¡n
    """)

st.markdown("---")
st.info("ğŸ’¡ Tool nÃ y sá»­ dá»¥ng AI Ä‘á»ƒ phÃ¢n tÃ­ch vÄƒn báº£n vá»›i kháº£ nÄƒng tÃ¹y chá»‰nh cao.") 